{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Installations"
   ],
   "metadata": {
    "id": "b-OJTTUeBGB-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install numpy\n",
    "!pip install tensorflow-gpu\n",
    "!pip install cudatoolkit\n",
    "!pip install cudnn\n",
    "!pip install livelossplot"
   ],
   "metadata": {
    "id": "mcUDroJgBJFu"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Set base configurations"
   ],
   "metadata": {
    "id": "nHEZxo65A3-i"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FGW4-7N7A0aZ"
   },
   "outputs": [],
   "source": [
    "seed_value= 42\n",
    "\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)\n",
    "tf.keras.utils.set_random_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ],
   "metadata": {
    "id": "iomiI7SAC1a-"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import"
   ],
   "metadata": {
    "id": "vOWo15wYBUzb"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling2D, Conv2D, Flatten, UpSampling2D\n",
    "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D, BatchNormalization, Conv2DTranspose, concatenate\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import regularizers, optimizers, losses\n",
    "from livelossplot.inputs.tf_keras import PlotLossesCallback"
   ],
   "metadata": {
    "id": "fCETuUYQBYWA"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Initialization"
   ],
   "metadata": {
    "id": "Gf7wd3EQChEx"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "num_epochs  =\n",
    "batch_size  =\n",
    "cls_num     =\n",
    "shape       =\n",
    "lr          =\n",
    "opt         = optimizers.Adamax(learning_rate=lr)\n",
    "los         = losses.BinaryCrossentropy()\n",
    "mtr         = []"
   ],
   "metadata": {
    "id": "2HBks-vyCjwu"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "address         =\n",
    "address_train   =\n",
    "address_test    =\n",
    "address_val     =\n",
    "\n",
    "data_train      = os.listdir(address_train)\n",
    "data_test       = os.listdir(address_test)\n",
    "data_val        = os.listdir(address_val)\n",
    "\n",
    "steps_per_train =\n",
    "steps_per_test  =\n",
    "steps_per_val   ="
   ],
   "metadata": {
    "id": "DgCEa8LBE8Cm"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preparation"
   ],
   "metadata": {
    "id": "CHQyAIHqBZEu"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "_w1ZjgaZBa7A"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Functions"
   ],
   "metadata": {
    "id": "e7yphVc3Bbbt"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "s3ppuGDW9S8g"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data generator"
   ],
   "metadata": {
    "id": "DMjId1dv9WVQ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, address, data, shape, batch_size, cls_num, shuffle=True):\n",
    "        self.address    = address\n",
    "        self.data       = data\n",
    "        self.shape      = shape\n",
    "        self.batch_size = batch_size\n",
    "        self.cls_num    = cls_num\n",
    "        self.shuffle    = shuffle\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.data) / self.batch_size))\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes       = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        list_IDs_temp = [self.data[k] for k in indexes]\n",
    "        x, y          = self.__data_generation(list_IDs_temp)\n",
    "        return x, y\n",
    "\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.data))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        x = np.empty((self.batch_size, int(self.shape[0]), int(self.shape[1]), int(self.shape[2])))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            x[i,] =\n",
    "            y[i]  =\n",
    "\n",
    "        return x, to_categorical(y, num_classes=self.cls_num)\n",
    "\n",
    "\n",
    "train_gen = DataGenerator(address_train, data_train, shape, batch_size, cls_num)\n",
    "test_gen  = DataGenerator(address_test , data_test , shape, batch_size, cls_num)\n",
    "val_gen   = DataGenerator(address_val  , data_val  , shape, batch_size, cls_num)"
   ],
   "metadata": {
    "id": "Lqfej_YmBcp0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {
    "id": "fFEJYG-GBdI-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def get_model(myshape, cls_num):\n",
    "\n",
    "  ##############################################################################\n",
    "\n",
    "  pad =\n",
    "  act =\n",
    "  ect =\n",
    "  drp =\n",
    "\n",
    "  ##############################################################################\n",
    "\n",
    "  inputt = Input(shape=myshape)\n",
    "\n",
    "  ##############################################################################\n",
    "\n",
    "  x = Flatten()(y)\n",
    "\n",
    "  outputt = Dense(cls_num, activation=ect)(x)\n",
    "\n",
    "  return Model(inputs=inputt, outputs=outputt)\n",
    "\n",
    "model = get_model()\n",
    "model.compile(optimizer=opt, loss=los, metrics=mtr)\n",
    "model.summary()"
   ],
   "metadata": {
    "id": "Epe7Q_oqBeEr"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train"
   ],
   "metadata": {
    "id": "lzs7DO9MBenF"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def callback():\n",
    "  mymonitor = 'val_loss'\n",
    "  mymode    = 'min'\n",
    "\n",
    "  main_chk  = ModelCheckpoint(filepath='my_checkpoint', monitor=mymonitor, mode=,mymode verbose=1, save_best_only=True)\n",
    "  early_st  = EarlyStopping(monitor=mymonitor, mode=mymode, patience=30, verbose=1)\n",
    "  rduce_lr  = ReduceLROnPlateau(monitor=mymonitor, mode=mymode, factor=0.5, patience=5, verbose=1, min_lr=0.0001)\n",
    "  tr_plot   = TrainingPlot()\n",
    "\n",
    "  return [main_chk, early_st, rduce_lr, tr_plot]\n",
    "\n",
    "history = model.fit(train_gen,\n",
    "                    validation_data=val_gen,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=num_epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks=callback(),\n",
    "                    steps_per_epoch  = steps_per_train,\n",
    "                    validation_steps = steps_per_val)"
   ],
   "metadata": {
    "id": "v-XEoecuBfmN"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation"
   ],
   "metadata": {
    "id": "WnhMRDgNBgIN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "testmodel = load_model('my_checkpoint', compile=True)\n",
    "tst_loss , tst_acc = testmodel.evaluate(test_gen, steps = steps_per_test)"
   ],
   "metadata": {
    "id": "h2ceCOoJBicL"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
